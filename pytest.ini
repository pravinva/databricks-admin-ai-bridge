[pytest]
# Pytest configuration for Databricks Admin AI Bridge

# Test markers
markers =
    unit: Unit tests with mocked dependencies (fast, no external calls)
    integration: Integration tests against real Databricks workspace (slow, requires auth)
    e2e: End-to-end agent tests with deployment and safety validation (requires workspace and agent)
    jobs: Tests for JobsAdmin functionality
    dbsql: Tests for DBSQLAdmin functionality
    clusters: Tests for ClustersAdmin functionality
    security: Tests for SecurityAdmin functionality
    usage: Tests for UsageAdmin functionality
    audit: Tests for AuditAdmin functionality
    pipelines: Tests for PipelinesAdmin functionality
    tools: Tests for Databricks agent tools

# Test discovery patterns
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test paths
testpaths = tests

# Output options
addopts =
    --strict-markers
    --verbose
    --tb=short
    --color=yes
    -ra

# Logging
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] [%(name)s] %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Coverage options (when using pytest-cov)
[coverage:run]
source = admin_ai_bridge
omit =
    */tests/*
    */test_*.py
    */__pycache__/*

[coverage:report]
precision = 2
show_missing = true
skip_covered = false

# Ignore patterns
[coverage:paths]
source =
    admin_ai_bridge/
    */site-packages/admin_ai_bridge/
